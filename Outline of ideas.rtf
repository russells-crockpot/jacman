{\rtf1\ansi\deff1\adeflang1025
{\fonttbl{\f0\froman\fprq2\fcharset0 Liberation Serif{\*\falt Times New Roman};}{\f1\fswiss\fprq2\fcharset128 DejaVu Sans;}{\f2\fswiss\fprq2\fcharset128 Bitstream Vera Sans;}{\f3\fnil\fprq0\fcharset0 Bitstream Vera Sans;}{\f4\fswiss\fprq0\fcharset0 Bitstream Vera Sans;}{\f5\fswiss\fprq2\fcharset128 DejaVu Sans;}}
{\colortbl;\red0\green0\blue0;\red128\green128\blue128;}
{\stylesheet{\s1\cf1\rtlch\af1\afs24\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs24\lang1033\loch\f1\fs24\lang1033\snext1 Normal;}
{\s2\sb240\sa120\cf1\rtlch\af2\afs28\lang255\ltrch\dbch\af2\langfe255\hich\f2\fs28\lang1033\loch\f2\fs28\lang1033\sbasedon1\snext3 Heading;}
{\s3\sa120\cf1\rtlch\af1\afs24\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs24\lang1033\loch\f1\fs24\lang1033\sbasedon1\snext3 Body Text;}
{\s4\sa120\cf1\rtlch\af2\afs24\lang255\ltrch\dbch\af2\langfe255\hich\f2\fs24\lang1033\loch\f2\fs24\lang1033\sbasedon3\snext4 List;}
{\s5\sb120\sa120\cf1\rtlch\af1\afs24\lang255\ai\ltrch\dbch\af1\langfe255\hich\f3\fs24\lang1033\i\loch\f3\fs24\lang1033\i\sbasedon1\snext5 caption;}
{\s6\cf1\rtlch\af2\afs24\lang255\ltrch\dbch\af2\langfe255\hich\f2\fs24\lang1033\loch\f2\fs24\lang1033\sbasedon1\snext6 Index;}
{\s7\sb120\sa120\cf1\rtlch\af4\afs24\lang255\ai\ltrch\dbch\af1\langfe255\hich\f4\fs24\lang1033\i\loch\f4\fs24\lang1033\i\sbasedon1\snext7 caption;}
{\s8\sb120\sa120\cf1\rtlch\af2\afs24\lang255\ai\ltrch\dbch\af2\langfe255\hich\f2\fs24\lang1033\i\loch\f2\fs24\lang1033\i\snext8 WW-caption;}
{\s9\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033\snext9 Standard;}
{\s10\cf1\qc\rtlch\af1\afs48\lang255\ab\ltrch\dbch\af1\langfe255\hich\f1\fs48\lang1033\b\loch\f1\fs48\lang1033\b\snext9 Document Title;}
{\s11\cf1\rtlch\af1\afs40\lang255\ab\ltrch\dbch\af1\langfe255\hich\f1\fs40\lang1033\b\loch\f1\fs40\lang1033\b\snext9 Head 1;}
{\s12\cf1\rtlch\af1\afs32\lang255\ab\ltrch\dbch\af1\langfe255\hich\f1\fs32\lang1033\b\loch\f1\fs32\lang1033\b\snext9 Head 2;}
{\s13\cf1\rtlch\af1\afs24\lang255\ab\ltrch\dbch\af1\langfe255\hich\f1\fs24\lang1033\b\loch\f1\fs24\lang1033\b\snext9 Head 3;}
{\s14\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033\snext14 Enumerated List;}
{\s15\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033\snext15 Alphabetical List;}
{\s16\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033\snext16 Bullet List;}
{\s17\li283\ri0\lin283\rin0\fi-283\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033\sbasedon1\snext17 footnote text;}
{\s18\cf1\rtlch\af1\afs24\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs24\lang1033\loch\f1\fs24\lang1033\sbasedon1\snext18 Table Contents;}
{\s19\cf1\qc\rtlch\af1\afs24\lang255\ab\ltrch\dbch\af1\langfe255\hich\f1\fs24\lang1033\b\loch\f1\fs24\lang1033\b\sbasedon18\snext19 Table Heading;}
{\s20\li283\ri0\lin283\rin0\fi-283\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033\sbasedon1\snext20 footnote text;}
{\*\cs22\rtlch\afs24\lang255\ltrch\dbch\langfe255\hich\fs24\lang1033\loch\fs24\lang1033 Footnote Symbol;}
{\*\cs23{\*\updnprop10000}\up2\rtlch\afs24\lang255\ltrch\dbch\langfe255\hich\fs24\lang1033\loch\fs24\lang1033 Footnote anchor;}
{\*\cs24\cf0\rtlch\af1\afs24\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs24\lang1033\loch\f1\fs24\lang1033 Footnote Symbol;}
}
{\info{\creatim\yr0\mo0\dy0\hr0\min0}{\revtim\yr0\mo0\dy0\hr0\min0}{\printim\yr0\mo0\dy0\hr0\min0}{\comment StarWriter}{\vern6800}}\deftab720
{\*\pgdsctbl
{\pgdsc0\pgdscuse195\pgwsxn12245\pghsxn15817\marglsxn1133\margrsxn1133\margtsxn850\margbsxn850\pgdscnxt0 Standard;}}
{\*\pgdscno0}\paperh15817\paperw12245\margl1133\margr1133\margt850\margb850\sectd\sbknone\pgwsxn12245\pghsxn15817\marglsxn1133\margrsxn1133\margtsxn850\margbsxn850\ftnbj\ftnstart1\ftnrstcont\ftnnar\aenddoc\aftnrstcont\aftnstart1\aftnnrlc
\pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033{\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Outline of ideas}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033{\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 The first input of our ANN should represent the current state of the enemies. That is}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Each enemy has a nerve cluster of 4 neurons. The Neurons represent the following:}
\par \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrt\brdrs\brdrw1\brdrcf1\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2283\clbrdrt\brdrs\brdrw1\brdrcf1\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 0}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 North}
\cell\row\pard \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2283\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 1}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 South}
\cell\row\pard \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2283\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 2}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 East}
\cell\row\pard \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2283\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 3}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 West}
\cell\row\pard \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 The enemy should choose the direction that has the highest activation. If the enemy cannot move in that direction, then the next highest is chosen, et cetera. The nerve cluster is a part of the output layer in the ANN.}
\par \pard\plain \ltrpar\s1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 The ANN should be trained initially, but it should also be further trained through out the game. First there should be 2 constants: BIG_LEARNING_RATE (BLR) and SMALL_LEARNING_RATE (SLR). For each of these, there is one negative and one positive. A positive
 reinforces the current weights, and the negatives adjusts them towards a different direction.}
\par \pard\plain \ltrpar\s1\cf1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 
\par \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrt\brdrs\brdrw1\brdrcf1\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Positive}
\cell\row\pard \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2442\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 BLR}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Kill enemy}
\cell\row\pard \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2442\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 SLR}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Reach regen point when dead}
\cell\row\pard \pard\plain \ltrpar\s1\cf1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 
\par \pard\plain \ltrpar\s1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 
\par \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrt\brdrs\brdrw1\brdrcf1\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Negative}
\cell\row\pard \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2513\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 BLR}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Enemy dies}
\cell\row\pard \trowd\trql\trpaddft3\trpaddt55\trpaddfl3\trpaddl55\trpaddfb3\trpaddb55\trpaddfr3\trpaddr55\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\cellx2513\clbrdrl\brdrs\brdrw1\brdrcf1\clbrdrb\brdrs\brdrw1\brdrcf1\clbrdrr\brdrs\brdrw1\brdrcf1\cellx9979
\pard\intbl\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 SLR}
\cell\pard\plain \intbl\ltrpar\s18\cf1\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Player gets a power blip}
\cell\row\pard \pard\plain \ltrpar\s9\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 
\par \pard\plain \ltrpar\s9\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 These allow the net to have weakly supervised learning. In the actual implementation,  since killing a player is rare, and an enemy dying is regular, a constant modifier may need to be needed. Either way, the net should not count the current state of the b
oard as the one to change, EG: if the enemy just killed the player, then we should not adjust the weights for the current board conditions. }
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 The reason for this is simple. Let us assume that an enemy just died. We want him to know that he shouldn't go towards the player. However, if we update the current state, then all it will teach him is that he should run away WHEN HE IS RIGHT NEXT TO THE P
LAYER. This is obviously not what we want. Therefore, instead, in the actual implementation, we should adjust the net according to the past. Therefore, we need to keep and actual list of the previous states. This is best accomplished with a queue of a set 
size. That is, when we add a new item to the queue, if that item would put us above the set size, then we remove the first item.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 In the actual implementation of the game, we use a Queue of size 20. The logic behind this is once again rather simple. One tile back is not enough to teach the AI, because often, one tile back is a simple corridor (IE: NS or EW). Therefore we want it to b
e at least 2 tiles back. The way we get 20 is through what is considered bad programming practice in all things but game programming:}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 The tile size is constant as 40 by 40.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Similarly, the movement rate is constant at 4.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Therefore, to traverse 1 tile, it takes 10 moves (tile size / movement rate).}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 So, if we want 2 tiles back, it's that times 2.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 A new class is implemented instead of a derivation of the standard Queue class because we need not worry about multi-threading, and can therefore reduce a GREAT deal of the overhead.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 However, we are not done yet. If we always have our net use the same BLR or SLR, then our net can never fine tune itself. That is, a constant learning rate may make our AI learn faster, but it will never learn very well. Therefore, we want a variable learn
ing rate. However, the heuristic proposed by R. A. Jacobs (1988) will not do. In that version, the learning rate increased if the error ratio changed in the same direction for several epochs, and it decreased if it would decrease if it alternated for sever
al epochs. Right away there are several problems with this, first of all, with our model, we have no defined idea of what an epoch is. Traditionally, an epoch is one iteration through a set of training data. However, here our training data isn't constant. 
We have no set number of cases that define an epoch, and therefore we cannot use this heuristic. Furthermore, even if we were able to, it would be unwise. With multi-layer networks (which is what we are using), this heuristic has a tendency to do one of 2 
things: make the network learn a great deal faster or make the network unable to learn the data at all. However, it should be noted, that while this heuristic has that tendency, since it is a heuristic, and not an algorithm, there is no one set way to do i
t, and therefore it is possible that this heuristic could be adapted for our game. But such tweaking, while it could be fruitful, is, ultimately, unneeded.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 For our purposes, and the purposes of many games, simpler is better. As ANN's imitate human brains, we can extend our ANN to learn as we know we do. Consider the following:}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\tx140\li660\ri0\lin660\rin0\fi0\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 When we learn something, we usually need to learn the basics/general concepts from a teacher (while this is not always needed, it makes for quicker learning). Once we have these basic concepts down, we can usually teach ourselves the specifics through expe
rience.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 For our purposes, we teach our AI the basics via the Trainer program. This is what we want, because otherwise our enemies would wander mindlessly for a very long time, that is, until they had learned. However, as stated earlier, once this initial training 
is completed, we want our AI to fine tune itself. After all, what the fuck is the point of using an ANN for a Pac-man clone unless it can adapt and learn?}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 To this end we can use a {\rtlch\ltrch\hich\i\loch\i somewhat} similar heuristic as that purposed by R. A. Jacobs. In our model, however, we only ever want our LR (learning rate) to get smaller. That is, as the AI gets further and further, we want it to tune itself to be finer and fin
er. There are several ways to do this, as with most any heuristic:}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 1) Change the LR when the error gradient gets low enough.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 2) When we've adjusted the net's weights a constant number of times.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\li0\ri0\lin0\rin0\fi660\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 3) When we've adjusted the net's weights a variable number of times.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 Notice that in all of these, an extra number N is needed. In the first example, we obviously can't change the LR when our error gradient is below a constant, otherwise we would be adjusting the LR every step once it got below the designated error gradient.
 Therefore, this can be considered  almost exactly tha same as the next two items. However, the process for computing the error gradient is somewhat slow and, therefore, ill advised within the setting of a game. Furthermore, with this model, it would make 
sense that when the enemy makes a large mistake, we would want the LR to increase, which simply puts us back at the heuristic given by R. A. Jacobs. Our second model may seem more fitting at first, however, once again, consider the way humans learn. Once w
e get good at something, does it takes us just as long to get twice as good at said something? In the vast majority of cases, this is not the case. As we get better at something, it gets harder and harder to get better at it. Therefore, with both considera
tions of logic and speed, the third option is obviously the best.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 \tab The obvious question about the 3{{\*\updnprop5801}\up8 rd} item is: how should we adjust our LR? Should this be constant or variable? This author's personal belief is that it should be variable, and that at some point in the future, a computer scientist will come up with an equa
tion of how to adjust this rate. However, since that has yet to happen, a constant multiple M would probably be wise. Whenever the LR changes, we should also adjust M. In our case we shall have M = M/2. For JacMan, though, the initial M = 0.5.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 \tab There is one question remaining: when we tell our network which direction it should have gone, which direction do we choose? EG: Let's say Enemy E{{\*\updnprop10000}\dn4 1} was going North, but gets eaten. When we readjust our weights, we need to tell it which direction it should
've gone, but which direction is that? Once again, this is the place of a heuristic. We cannot automatically and systematically with complete certainty (that is algortimically) tell it which way it should have gone. We must consider the way our ANN is setu
p, and what information it gives us. Since we have the player's row represented by an on bit in one cluster of neurons, and the column in another, we cannot tell for sure which is closer, the x or the y, without significant change to our ANN's infrastructu
re. But such a change to our infrastructure would not only be annoying to implement, but it would also greatly slow our gameplay down, which is unacceptable in most games. Therefore, it is best that we work with what we have instead of refractoring. The he
uristic (to be implemented) is as follows:}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 \tab If we were going in the y direction, then we should have been going in the x direction.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 \tab If we were going in the x direction, then we should have been going in the y direction.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 There is, however, an obvious flaw with this idea. We may end up training our network to go in a direction that is inaccessible. Luckily, part of our net also tells us the move options for the enemies. To explain our heuristic, let's use an example. Let's 
say that our enemy had the options of NSEW; it choses to go South and was eaten. Our obvious first choice would be to go in the opposite direction, North, and our last choice is the direction it went, South. As for the middle two, our second choice should 
have been the one that would go further away from the player in the x plane. That is, let's assume that the player was to the East of the enemy eaten, then our second choice would be West, and our third East. Should any of these options be inaccessible to 
us, then we merely put it at the bottom of our choices an use the next one as the first.}
\par \pard\plain \ltrpar\s9\cf1\sl360\slmult1\ql\rtlch\af1\afs20\lang255\ltrch\dbch\af1\langfe255\hich\f1\fs20\lang1033\loch\f1\fs20\lang1033 {\rtlch \ltrch\loch\f1\fs20\lang1033\i0\b0 \tab Now, there is one more thing we want, which should be implemented last: Blips; specifically, Power Blips. Power blips are what switch the state of the enemy from hunter to hunted. If the player is about to eat a PB (Power Blip), then we want our enemy to 
run away, not continue the pursuit of our player. However, our board is also littered with PB's. Should we train our ANN ignoring PB's than in all likeliness, one of two things would happen: Our enemies would always run away, or our enemies would ignore th
e PB's completely. The first problem ac be solved with a constant multiplier (as mentioned previously). The second one, then, is what we need to deal with. Now there are several options of how to deal with th PB problem. We could make game play a little le
ss interesting by ignoring it, but, as also stated earlier, when you're using an ANN for a Pac-man clone, then what is the point of not adapting. That is, why should someone play Jac-man instead of a Pac-man ROM when our AI performs only slightly better? T
he answer, ignoring legal issues, is that they shouldn't. Therefore, we want our net to take these PB's into consideration. Now, as usual, there are several ways to implement these. The first obvious choice is to represent each position of a power blip as 
we did of each enemy; that is for each power blip, we could have a number of neurons equal to the number of rows, with all being zero except of the row in which the power blip is located, which would be 1; the same would be true for columns. However, this 
is most certainly excessive. In our ANN, the reason we have our a row representing each player/enemy is because these {\rtlch\ltrch\dbch\hich\i\loch\i change}{. Power blips never move, therefore, we can represent them a different, much simpler way: one neuron for one power blip. This way ou
r net can still ultimately learn what we want it to,  but sacrifice little time a processing power.}}
\par }